---
layout: home
title: Andre Kassis
subtitle: Machine Learning Security and Privacy Researcher
---

<p> I am a Ph.D. candidate in Computer Science at the <a href="https://uwaterloo.ca/">University of Waterloo</a>, advised by <a href="https://cs.uwaterloo.ca/~uhengart/">Prof. Urs Hengartner</a>. I conduct my research at the Cryptography, Security, and Privacy (<a href="https://crysp.uwaterloo.ca/">CrySP</a>) Lab, focusing on ML security and robustness. Before that, I earned my B.Sc. in Computer Engineering (Summa Cum Laude) from the <a href="https://www.technion.ac.il/en/">Technion – Israel Institute of Technology</a>, where I specialized in computer security and machine learning.</p>	
<p>My research focuses on uncovering and mitigating vulnerabilities in machine learning systems, with a particular emphasis on adversarial attacks, secure authentication, and watermarking techniques. My recent work explores critical areas of AI security, including bypassing defensive watermarking (<a href="https://arxiv.org/abs/2405.08363">UnMarker</a>), breaking diffusion-based purification methods (<a href="https://arxiv.org/abs/2411.16598">DiffBreak</a>), and attacking <a href="https://ieeexplore.ieee.org/document/10179374">security-critical voice authentication systems</a>. Through this research, I aim to bridge the gap between theory and application in adversarial machine learning, developing robust, interpretable, and attack-resistant AI systems that can be safely deployed in real-world applications. I am currently working on enhancing the robustness of diffusion-based purification against adversarial examples via backdoors.
<p>Beyond academia, I have worked at <a href="https://research.ibm.com/labs/israel">IBM Research</a> and <a href="https://www.pindrop.com/">Pindrop Security</a>, where I applied my expertise to cloud security, biometric authentication, and adversarial ML. I am always open to collaborations and discussions on AI security, so feel free to reach out via email!</p>
<p><a href="https://drive.google.com/file/d/1B77avcMiZwONaJGL3eEs7-uznb7lGzHn/view?usp=sharing">CV</a>, <a href="https://scholar.google.ca/citations?view_op=list_works&hl=en&user=2VYc0T8AAAAJ">Google Scholar</a>,  <a href="https://www.linkedin.com/in/andrekassis7">LinkedIn</a> </p>

<!-- SELECTED PUBLICATIONS########################################################################### -->
<article>

  <center> <h2>Publications</h2></center> 
	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">DiffBreak: Is Diffusion-Based Purification Robust?</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li style="text-align: justify;"><em>The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025.</em></li>
		<li><strong>Andre Kassis</strong>, Urs Hengartner, Yaoliang Yu</em></li>
		<li><em>Sole Student Author – Fully Led Research & Writing.</em> <a href="https://arxiv.org/abs/2411.16598">Paper</a>, <a href="https://github.com/andrekassis/DiffBreak">Code</a></li>
		<p>DiffBreak challenges diffusion-based purification (DBP), a widely regarded defense against adversarial attacks. Contrary to common belief, DiffBreak theoretically proves that gradient-based adaptive attacks on DBP do not merely aim to generate perturbations that survive purification—they actively repurpose it as an adversarial generator. Rather than neutralizing adversarial optimization, DBP shifts it from the classifier to the score model, leaving it highly vulnerable and invalidating its formal guarantees. This discovery prompts a reassessment of DBP’s robustness, showing its security stems from attack backpropagation flaws rather than actual resilience. DiffBreak introduces a reliable gradient library that reveals how adaptive attacks drastically degrade DBP’s effectiveness. It also proposes an adversarial optimization method that reduces DBP’s robustness to nearly 0%, even under the strictest threat models.</p>
		</ul>
	<h3>&nbsp;</h3>	

	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">UnMarker: A Universal Attack on Defensive Image Watermarking.</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li style="text-align: justify;"><em>46th IEEE Symposium on Security and Privacy, 2025.</em></li>
		<li><strong>Andre Kassis</strong> and Urs Hengartner</em></li>
		<li><em>Sole Student Author – Fully Led Research & Writing.</em> <a href="https://arxiv.org/abs/2405.08363">Paper</a>, <a href="https://github.com/andrekassis/ai-watermark">Code</a></li>
		<li><em>Media Coverage: </em><a href="https://spectrum.ieee.org/ai-watermark-remover?share_id=8924479">IEEE Spectrum</a>, <a href="https://www.theregister.com/2025/07/24/ai_watermarks_unmarker/">The Register</a>, <a href="https://www.thestar.com/business/canadian-researchers-create-tool-to-remove-anti-deepfake-watermarks-from-ai-content/article_3dbbc1b7-63af-596c-a732-116a33786524.html">Toronto Star</a>, <a href="https://www.theglobeandmail.com/business/article-researchers-create-tool-to-remove-anti-deepfake-watermarks-point-out/">The Globe & Mail</a>, <a href="https://www.cbc.ca/listen/live-radio/1-2-as-it-happens/clip/16159987-hockey-canada-players-found-guilty-sexual-assault">CBC Radio</a></li>
		<p>UnMarker is a universal attack that effectively bypasses defensive image watermarking techniques, exposing their fundamental weaknesses. In this work, We demonstrate how adaptive spectral adversarial perturbations can remove or distort embedded watermarks without compromising image quality, rendering watermarking-based security measures ineffective. UnMarker systematically evaluates a wide range of watermarking schemes, including traditional and deep learning-based approaches, revealing their susceptibility to carefully crafted attacks and driving their robustness below 50%.</p>
		</ul>
	<h3>&nbsp;</h3>	

	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">Breaking Security-Critical Voice Authentication.</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li style="text-align: justify;"><em>44th IEEE Symposium on Security and Privacy, 2023.</em></li>
		<li><strong>Andre Kassis</strong> and Urs Hengartner</em></li>
		<li><em>Sole Student Author – Fully Led Research & Writing.</em> <a href="https://ieeexplore.ieee.org/document/10179374">Paper</a>, <a href="https://github.com/andrekassis/Breaking-Security-Critical-Voice-Authentication">Code</a></li>
		<li><em>Media Coverage: </em><a href="https://technews.acm.org/archives.cfm?fo=2023-06-jun/jun-28-2023.html">ACM TechNews</a>, <a href="https://www.theregister.com/2023/06/28/adversarial_ai_audio_authentication_research/">The Register</a>, <a href="https://www.pcmag.com/news/deepfake-software-fools-voice-authentication-with-99-success-rate">PCMag</a>, <a href="https://catless.ncl.ac.uk/Risks/33/74/#subj15.1">RISK Digest</a>, <a href="https://www.therecord.com/news/waterloo-region/the-era-of-deepfakes-uw-researchers-use-ai-to-expose-the-weakness-in-voice-authentication/article_1ef2bb07-39ed-5846-82e9-4860b31681b1.html">The Record</a></li>
		<p>This paper presents the first practical attack on voice authentication (VA) used in security-critical applications like banking and secure access control. We demonstrate that attackers can generate and adversarially optimize fake audio samples to universally bypass VA systems. Our results show that attackers achieve up to 99% success in just six attempts, exposing severe vulnerabilities in real-world biometric authentication and challenging its reliability.</p>
		</ul>
	<h3>&nbsp;</h3>	

	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">Practical attacks on voice spoofing countermeasures.</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li><strong>Andre Kassis</strong> and Urs Hengartner</em></li>
		<li><a href="https://arxiv.org/abs/2107.14642">arXiv Preprint</a></li>
		</ul>
	<h3>&nbsp;</h3>	

	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">Estimating client QoE from measured network QoS.</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li style="text-align: justify;"><em>Proceedings of the 12th ACM International Conference on Systems and Storage, 2019.</em></li>
		<li>Kenneth Nagin, <strong>Andre Kassis</strong>, Dean Lorenz, Katherine Barabash, Eran Raichstein</em></li>
		<li><a href="https://dl.acm.org/doi/abs/10.1145/3319647.3325849">Paper</a></li>
		</ul>
	<h3>&nbsp;</h3>	

	<h3 style="text-align: justify;color: inherit;"><a style="color: inherit;" target="_blank" rel="noopener">Deep ahead-of-threat virtual patching.</a></h3>
	<h3></h3>
		<ul style="list-style: none;">
		<li style="text-align: justify;"><em>Information and Operational Technology Security Systems: First International Workshop, IOSec 2018, CIPSEC Project.</em></li>
		<li>Fady Copty, <strong>Andre Kassis</strong>, Sharon Keidar-Barner and Dov Murik</em></li>
		<li><a href="https://link.springer.com/chapter/10.1007/978-3-030-12085-6_9">Paper</a></li>
		</ul>
	<h3>&nbsp;</h3>	
</article>
